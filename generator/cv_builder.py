# generator/cv_builder.py
import os
import json
import re
from openai import OpenAI
from generator.config import OPENAI_API_KEY, SYSTEM_PROMPT, LINKEDIN_PROFILE

# Initialize OpenAI client
client = OpenAI(api_key=OPENAI_API_KEY)


# ================================
# Load Base CV
# ================================
def load_base_cv():
    """Load your base CV (used as the only source of truth)."""
    with open("data/base_cv.txt", "r", encoding="utf-8") as f:
        return f.read().strip()


BASE_CV = load_base_cv()


# ================================
# Load Few-Shot Examples (optional)
# ================================
def load_examples():
    try:
        with open("data/examples.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return []


EXAMPLES = load_examples()


# ================================
# Utility: Clean markdown artifacts
# ================================
def clean(text):
    """Remove markdown bold/italic formatting generated by the model."""
    text = re.sub(r"\*\*(.*?)\*\*", r"\1", text)
    text = re.sub(r"\*(.*?)\*", r"\1", text)
    return text.strip()


# ================================
# Build Few-Shot Prompt
# ================================
def build_prompt(job_desc):
    """Build the full user prompt including examples + job description + base CV."""
    fewshot = ""

    for ex in EXAMPLES[:3]:
        fewshot += (
            f"Job Description:\n{ex['job_desc']}\n"
            f"Tailored CV:\n{ex['tailored_cv']}\n\n"
        )

    return (
        f"Examples:\n{fewshot}"
        f"Job Description:\n{job_desc}\n\n"
        f"Base CV:\n{BASE_CV}\n\n"
        f"Tailored CV:"
    )


# ================================
# Generate CV (HTML + PDF-Safe)
# ================================
def generate_cv(job_desc, custom_prompt=None):
    """
    Produce two versions:
    - HTML/TXT version (header with plain text)
    - PDF-safe version (header with <link> tag)
    """

    system_prompt = custom_prompt if custom_prompt else SYSTEM_PROMPT
    prompt = build_prompt(job_desc)

    # GPT Call
    response = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.6,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt},
        ],
    )

    content = clean(response.choices[0].message.content)

    # Force SUMMARY to appear first
    if not content.upper().startswith("SUMMARY"):
        content = "SUMMARY\n" + content

    # =============================
    # Headers
    # =============================

    # Header for TXT/HTML (plain)
    header_html = (
        "LIRAN ROTH\n"
        "Israel | LinkedIn | 0542223310 | liranrothwork@gmail.com\n\n"
    )

    # Header for PDF — MUST be one continuous line (ReportLab hyperlink uses <link>)
    header_pdf = (
        f"LIRAN ROTH — Israel | "
        f"<link href='{LINKEDIN_PROFILE}'>LinkedIn</link> | "
        "0542223310 | liranrothwork@gmail.com"
    )

    # Return both versions
    return header_html + content, header_pdf + content
